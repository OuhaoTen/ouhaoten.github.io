[{"content":"ä¸€.è®ºæ–‡æ€»è§ˆ é—®é¢˜èƒŒæ™¯ï¼š ç°æœ‰çš„å°†å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMultimodal Large Language Model, MLLMï¼‰å¼•å…¥è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„æ–¹æ³•ä¸­ï¼Œå¤§å¤šä¸å…·å¤‡3Dåœºæ™¯ç†è§£èƒ½åŠ›ï¼Œä½†è¿™ä¸€èƒ½åŠ›å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯è€Œè¨€æ˜¯ä¸å¯æˆ–ç¼ºçš„ï¼Œä»¥ä¸€ä¸ªé©¾é©¶åœºæ™¯ä¸­å¸¸è§çš„é—®é¢˜ä¸ºä¾‹ï¼šâ€œè¯¢é—®å½“å‰è½¦é“æ˜¯å¦å¯ä»¥å·¦è½¬â€ï¼Œè¯¥é—®é¢˜çœ‹ä¼¼åœ¨åšä¸€ä¸ªç®€å•çš„è¯­ä¹‰åˆ¤æ–­ï¼Œæœ¬è´¨ä¸Šéœ€è¦æ¶‰åŠåˆ°å¯¹è½¦é“ä¸è‡ªè½¦çš„å‡ ä½•å…³ç³»åˆ¤æ–­ã€è½¦é“ä¸äº¤é€šç¯è¯­ä¹‰ã€åœ°é¢æ ‡è¯†è¯­ä¹‰çš„åŒ¹é…ï¼Œè¦å›ç­”è¿™äº›é—®é¢˜ï¼Œéœ€è¦ MLLM æ¨¡å‹å°† 2D ç†è§£å’Œæ¨ç†èƒ½åŠ›æ‰©å±•åˆ°å¤æ‚çš„ 3Dåœºæ™¯ä¸­ã€‚ ç°æœ‰ MLLM æ¨¡å‹æŒ‰ç…§å¯¹å›¾åƒçš„å¤„ç†æ–¹å¼çš„ä¸åŒï¼Œå¯ä»¥åˆ†ä¸ºä¸¤ç§æµæ´¾ï¼šä¸€ç§æ˜¯ä»¥ Flamingo ã€BLIP-2ã€Qwenç­‰æ–¹æ³•ä¸ºä»£è¡¨ï¼Œä»¥äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¸ºåŸºç¡€ï¼Œç‰¹ç‚¹æ˜¯ä¸è®ºå›¾åƒåˆ†è¾¨ç‡éƒ½å¤„ç†æˆç»Ÿä¸€é•¿åº¦çš„ token åºåˆ—ï¼Œè€Œå¦ä¸€ç§æ˜¯ä»¥ Vitã€ BLIPã€LLAVA ä¸ºä»£è¡¨ï¼Œä»¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸ºåŸºç¡€ï¼Œæ¯ä¸ª token ç”¨äºä»£è¡¨å›ºå®šåƒç´ å¤§å°çš„å›¾åƒå±€éƒ¨ä¿¡æ¯ï¼Œè¿™æ„å‘³ç€ä¸åŒçš„åˆ†è¾¨ç‡å›¾åƒå¯¹åº”å˜é•¿çš„ token åºåˆ—ã€‚å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯è€Œè¨€ï¼Œå¤šè§†è§’ã€é«˜åˆ†è¾¨ç‡ã€è¿ç»­å¸§ï¼ˆè§†é¢‘ï¼‰æ˜¯æ„ŸçŸ¥ä»»åŠ¡çš„æ•°æ®ç‰¹ç‚¹ï¼Œè€Œå˜é•¿åºåˆ—ä»£è¡¨æ—¶å»¶ã€ä¸ç¨³å®šã€‚æ‰€ä»¥ä½œè€…ä»¥ BLIP-2 ç»“æ„ä¸ºåŸºç¡€ï¼Œå¼•å…¥ Stream-PETRï¼ˆä½œè€…ä¹‹å‰çš„å·¥ä½œï¼‰ï¼Œæ„å»ºç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„ 3D MLLMã€‚ è¿‡å»çš„ Benchmark å¤§å¤šé‡‡ç”¨ç®€å•çš„ QA çš„å½¢å¼è¿›è¡Œè¯„æµ‹ï¼Œå·²æœ‰å·¥ä½œè¯æ˜ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç›®å‰ open-loop è¯„æµ‹æ–¹å¼çš„å±€é™æ€§ã€‚å¦å¤–ï¼Œè¿™ç§è¯„æµ‹æ–¹å¼é©±åŠ¨çš„æ–¹æ³•ä¹Ÿæ— æ³•å®Œå…¨åˆ©ç”¨åˆ°å¤§è¯­è¨€æ¨¡å‹å¼ºå¤§çš„æ¶Œç°èƒ½åŠ›ã€‚å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œç±»ä¼¼äºä¸–ç•Œæ¨¡å‹çš„åäº‹å®æ¨æ–­èƒ½åŠ›æ˜¯æ›´ç¬¦åˆäººç±»æ€è€ƒæ–¹å¼å’Œä¹ æƒ¯çš„ã€‚ä½œè€…å¸Œæœ›ä»¿ç…§ LLAVA çš„åšæ³•ï¼Œæå‡ºä¸€ç§é«˜æ•ˆçš„æ•°æ®æ„å»ºæ–¹å¼ï¼Œç”¨äºæ„å»ºå¤§è§„æ¨¡ VQA æ•°æ®é›†ï¼Œä¸€æ–¹é¢ç”¨äº MLLM çš„ Instruction-tuning è®­ç»ƒï¼Œå¦ä¸€æ–¹é¢ç”¨äºè¯„æµ‹ã€‚ è´¡çŒ®ï¼š ä¸€ç§å…·æœ‰3d èƒ½åŠ›çš„vision-language modelç»“æ„ï¼Œå°†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„3dåœºæ™¯ä»»åŠ¡ï¼› ä¸€ç§åŸºäº GPT-4o çš„æ•°æ®æ„å»ºæ–¹æ³•ï¼Œç”¨äºç”Ÿæˆè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„ VQA é—®ç­”æ•°æ®ï¼ŒåŒ…æ‹¬åäº‹å®æ¨æ–­å½¢å¼çš„é—®ç­”ã€‚ äºŒ.æ–¹æ³• ç»“æ„æ€»è§ˆï¼š å›¾åƒç¼–ç å™¨ï¼šä½œè€…é‡‡ç”¨çš„æ˜¯åŸºäº Clip ç»“æ„çš„ Eva-02 æ¨¡å‹ä½œä¸ºå›¾åƒç¼–ç å™¨ï¼Œé€šè¿‡å¤šè§†è§’å›¾åƒç‰¹å¾æå– 3d ä¿¡æ¯ï¼Œè¿™ä¸€éƒ¨åˆ†æ²¡å¤ªå¤šéœ€è¦è®²çš„ã€‚ Q-Former3Dï¼šå‚è€ƒ BLIP-2 ä¸­çš„ Q-Former ç»“æ„ï¼Œè¿™é‡Œä½œè€…æ•é”åœ°å‘ç°äº† Q-Former ç»“æ„å’Œ Petr ç³»åˆ—æ¨¡å‹ç»“æ„çš„ç›¸ä¼¼ä¹‹å¤„ï¼Œå°†ç»“æ„å¼•å…¥çš„åŒæ—¶ä¹Ÿå¼•å…¥äº† 3D ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä½œä¸ºè¾…åŠ©ç›‘ç£ã€‚ LLMï¼šä¹‹å‰çš„ç»“æ„çš„ä½œç”¨åœ¨äºæå– 3D ä¿¡æ¯ç‰¹å¾ï¼Œæœ€ç»ˆéœ€è¦å¯¹é½åˆ° LLM æ¨¡å‹èƒ½å¤Ÿç†è§£çš„ç‰¹å¾ç©ºé—´ï¼Œè¿›è¡Œ VQA é—®ç­”ã€‚ Q-Former3D: ä½œä¸ºæœ€èƒ½ä½“ç°ä½œè€…è´¡çŒ®çš„æ¨¡å—ï¼Œè¿™ä¸€éƒ¨åˆ†é€‰æ‹© Stream-PETR å‡ºäºä»¥ä¸‹è€ƒè™‘ï¼šPETR æ‰€ä»£è¡¨çš„ç¨€ç– BEV å»ºæ¨¡æ–¹å¼ï¼Œé€‚ç”¨äºæ£€æµ‹ä»»åŠ¡ï¼Œç›¸æ¯”äºéœ€è¦æ„å»º dense bev feature çš„æ–¹æ³•æ¥è¯´ï¼Œéœ€è¦æ›´å°çš„è®¡ç®—é‡ï¼ŒåŒæ—¶åŠ å¿«æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼Œæ¯•ç«ŸOmniDrive çš„æ ¸å¿ƒåœ¨äºå¤šæ¨¡æ€å¤§æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ£€æµ‹ä»»åŠ¡ä»…ä½œä¸ºè¾…åŠ©ç›‘ç£ï¼Œæ‰€ä»¥å°½é‡ç®€åŒ–é™ä½å­˜åœ¨æ„Ÿã€‚\nQ-Former3D æ•´ä½“ç»“æ„åŸºäº Stream-PETRï¼ŒåŒ…æ‹¬ Memery Bankæ—¶åºèåˆæ¨¡å—ï¼Œä½†è¿™ä¸æ˜¯æœ¬æ–‡ä»‹ç»çš„é‡ç‚¹ï¼Œå…ˆæŒ–ä¸€ä¸ªå‘ï¼Œä¼šå°½å¿«åœ¨å¦å¤–ä¸€ç¯‡åšå®¢ä¸­æ›´æ–°ä»‹ç» PETR ç³»åˆ—ã€‚\nè¿™é‡Œé‡ç‚¹ä»‹ç»ä½œè€…é¢å¤–çš„è®¾è®¡ï¼š\næ ¹æ®ä»»åŠ¡è®¾è®¡ä¸¤ç§ queryï¼šç”¨äº3D ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„ query ç§°ä¸º Perception queryï¼Œç”¨äº LLM ç”Ÿæˆæ–‡æœ¬ä»»åŠ¡çš„ç§°ä¸º Carrier queryã€‚\næŒ‰ç…§ PETR çš„è®¾è®¡ï¼Œè¿™ä¸¤ç§ query ä¼šåŠ å…¥ 3d ä½ç½®ç¼–ç ä¿¡æ¯åè¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ Carrier query ä¼šä¸ Perception query ä¸­ 3d ä»»åŠ¡ç›¸å…³ä¿¡æ¯äº¤äº’ï¼Œç”¨äºä¿è¯åç»­ LLM è¿›è¡Œæ–‡æœ¬ç”Ÿæˆæ—¶çš„ 3d åœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå¯¹åº”ä»¥ä¸‹è¿‡ç¨‹: $$ \\begin{array}{r} (Q, K, V)=\\left(\\left[Q_c, Q_d\\right],\\left[Q_c, Q_d\\right],\\left[Q_c, Q_d\\right]\\right), \\ \\tilde{Q}=\\operatorname{Multi-head} \\operatorname{Attention}(Q, K, V) \\end{array} $$\nä»¥ä¸Šæ‰€æœ‰ query åˆç§°ä¸º Qï¼Œå›¾åƒç¼–ç å™¨è¾“å‡ºçš„å›¾åƒç‰¹å¾ä¸ä½ç½®ç¼–ç ç›¸åŠ åä½œä¸º Kï¼Œå›¾åƒç‰¹å¾å•ç‹¬ä½œä¸º Vï¼Œè¿›è¡Œäº¤å‰æ³¨æ„åŠ›è®¡ç®—ã€‚è¿™ä¸€è¿‡ç¨‹ä¼šè¿›è¡Œå¤šå±‚ $$ \\begin{array}{r} (Q, K, V)=\\left(\\left[Q_c, Q_d\\right], P_m+F_m, F_m\\right), \\ \\tilde{Q}=\\operatorname{Multi-head\\operatorname {Attention}(Q,K,V)} \\end{array} $$\nä¸Šè¿°è¿‡ç¨‹ç»è¿‡å¤šå±‚åå¾—åˆ°è¾“å‡ºï¼ŒæŒ‰ç…§è¾“å…¥çš„åˆ’åˆ†ï¼ŒPerception query å¯¹åº”çš„è¾“å‡ºä¼šè¿›å…¥åˆ° PETR head è¿›è¡Œå‰æ™¯ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼›Carrier query å¯¹åº”çš„è¾“å‡ºä¼šç»è¿‡ MLP æ˜ å°„æˆ LLM çš„è¾“å…¥ç»´åº¦ï¼Œç„¶åé€å…¥ LLM è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œè¿™ä¸€åšæ³•å’Œ LLAVA ç›¸åŒã€‚ä»ç»“æœæ¥çœ‹ï¼ŒCarrier query çš„ä¸»è¦ä½œç”¨å°±æ˜¯ç”¨äºè§†è§‰è¯­è¨€ç‰¹å¾çš„å¯¹é½ï¼ŒåŒæ—¶åˆ©ç”¨åˆ° 3d å‡ ä½•å…ˆéªŒä¿¡æ¯å’Œ Perception query ä¸­çš„æ„ŸçŸ¥æ£€æµ‹ç»“æœä¿¡æ¯ã€‚\nè®­ç»ƒç­–ç•¥ è®­ç»ƒæ•´ä½“åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š\n2d é¢„è®­ç»ƒé˜¶æ®µï¼š\nè¿™ä¸€éƒ¨åˆ†å®é™…ä¸Šæ˜¯ä¸€ä¸ªå®Œæ•´çš„ LLM è®­ç»ƒè¿‡ç¨‹ï¼Œä¹Ÿéœ€è¦åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š\né¢„è®­ç»ƒï¼šè¿™ä¸ªé˜¶æ®µä¸æ¶‰åŠåˆ°perception queryçš„è®­ç»ƒï¼Œæ‰€ä»¥å‰©ä½™çš„éƒ¨åˆ†å’Œä¸€ä¸ªæ™®é€šçš„MLLMçš„è®­ç»ƒæ–¹å¼ä¸€æ ·ï¼Œè¿™é‡Œç”±äºæ¨¡å‹ç»“æ„æ˜¯Q-Formerå½¢å¼çš„ï¼Œæ‰€ä»¥é‡‡ç”¨BLIP-V2çš„è®­ç»ƒæ–¹å¼ï¼Œä½†æ˜¯ç”±äºæ²¡æœ‰BLIPä¸­çš„å¤šä¸ªdecoderç»“æ„ï¼Œæ‰€ä»¥åªèƒ½ä½¿ç”¨æ–‡æœ¬å»ºæ¨¡lossè¿›è¡Œç›‘ç£ï¼Œæ²¡æœ‰ä½¿ç”¨BLIPä¸­çš„å…¶ä»–çš„å¯¹æ¯”æŸå¤±å’ŒåŒ¹é…æŸå¤±ã€‚è¿™é‡Œä¸»è¦å°±æ˜¯å®Œæˆäº†Q-Formerçš„è®­ç»ƒï¼Œå®ç°äº†ä»å›¾åƒç‰¹å¾åˆ°æ–‡æœ¬ç‰¹å¾çš„å¯¹é½ã€‚\nInstruction-tuningé˜¶æ®µï¼šä½¿ç”¨çš„ä¹Ÿæ˜¯LLAVA-V1.5 ç”Ÿæˆçš„æ•°æ®é›†ã€‚\n3d fine-tune é˜¶æ®µï¼š\nè¿™ä¸€é˜¶æ®µçš„ç›®æ ‡æ˜¯å¢å¼ºæ¨¡å‹çš„3Dåœºæ™¯ç†è§£èƒ½åŠ›ï¼ŒåŒæ—¶å°½å¯èƒ½å¤šåœ°ä¿ç•™å…¶åŸæœ‰çš„2Dè¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚\næ€»ä½“ä½¿ç”¨Lora å¾®è°ƒï¼Œä»¥è¾ƒå°çš„å­¦ä¹ ç‡å¯¹è§†è§‰ç¼–ç å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä»¥ç›¸å¯¹è¾ƒå¤§çš„å­¦ä¹ ç‡è®­ç»ƒQ-Former3Dã€‚\nä»¥ä¸Šå°±æ˜¯å¯¹æ•´ä½“æ–¹æ³•æ¡†æ¶çš„è§£è¯»ï¼Œå¯ä»¥çœ‹å‡ºçš„æ˜¯ï¼šæ¨¡å‹æ•´ä½“çš„3d èƒ½åŠ›æ ¸å¿ƒå®é™…æ˜¯åœ¨äº Q-Former3D æ¨¡å—ï¼Œå¦å¤–å¤ç°å‘ç°æ–¹æ³•æ•´ä½“å¯¹äºå­¦ä¹ ç‡çš„è®¾ç½®æ¯”è¾ƒæ•æ„Ÿï¼Œå¹¶ä¸”åœ¨æ£€æµ‹ä»»åŠ¡æ˜æ˜¾æœªè¾¾åˆ°æ”¶æ•›æ—¶ï¼ŒLLM çš„planningä»»åŠ¡çš„æŸå¤±å·²æœ‰æ˜æ˜¾çš„æ”¶æ•›å€¾å‘ï¼Œä½œè€…åœ¨ issue ä¸­æœ‰æåˆ°ï¼Œæ£€æµ‹ä»»åŠ¡çš„æ”¶æ•›éœ€è¦ 24 ä¸ª epoch å·¦å³ï¼Œè€Œæœ€ç»ˆä½œè€…æä¾›çš„è®­ç»ƒé…ç½®åªæœ‰ 6 ä¸ª epochï¼ŒçŒœæµ‹è¿™ä¸€ç°è±¡æ˜¯ä¸ Q-Former3D çš„å¾®è°ƒé˜¶æ®µçš„å¤§å­¦ä¹ ç‡è®¾ç½®æœ‰å…³ã€‚\nä¸‰. ç»“æœ ç”±äºä½œè€…ä¸»è¦çš„å–ç‚¹åœ¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶åœ¨3d åœºæ™¯çš„æ•ˆæœå’Œåäº‹å®æ¨æ–­èƒ½åŠ›ï¼Œæ‰€ä»¥ä½œè€…å¹¶æ²¡æœ‰åˆ—å‡ºç›®æ ‡æ£€æµ‹çš„æŒ‡æ ‡ï¼Œä¸»è¦çš„å–ç‚¹è¿˜æ˜¯ä»¥ planning ä¸ºå¯¼å‘çš„ç«¯åˆ°ç«¯åœºæ™¯ï¼Œæ‰€ä»¥å¯¹æ¯”çš„ä¸»è¦æŒ‡æ ‡æ˜¯ open-loop planning è½¨è¿¹çš„ l2 è¯¯å·®ã€objectç¢°æ’ç‡ã€ä»¥åŠboundary ç¢°æ’ç‡ å¦å¤–ï¼Œå…³äºä½œè€…æå‡ºçš„ benchmarkï¼Œä½œè€…ä¹Ÿè¿›è¡Œäº†è¯¦ç»†çš„æ¶ˆèå®éªŒæ¥è¯æ˜å„ç±»å‹æ•°æ®çš„ä½œç”¨ï¼š\nå››.æ•°æ®ç”Ÿæˆé€»è¾‘è§£è¯» è¯¥å·¥ä½œçš„å¦ä¸€å¤§è´¡çŒ®æ˜¯åŸºäº GPT-4o çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œè™½ç„¶æ€»ä½“ä¸Šä¸ LLAVA çš„åšæ³•ç›¸ä¼¼ï¼Œä½†ä½œè€…å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„ä»»åŠ¡åšäº†ä¸€äº›åˆ«å‡ºå¿ƒè£çš„è®¾è®¡ï¼Œè¿™ä¸€éƒ¨åˆ†ä¼šè¯¦ç»†è§£è¯»ä½œè€…æ˜¯å¦‚ä½•å¤„ç† Nuscenes æ•°æ®é›†ä¿¡æ¯ï¼Œæä¾›ç»™ GPT ä½œä¸º promptï¼Œç”¨äºç”ŸæˆåŒ…å«åäº‹å®æ¨æ–­çš„å¯¹è¯ã€‚\né¦–å…ˆï¼Œä½œè€…æä¾›çš„ç¤ºä¾‹å›¾ä¸­ï¼Œå°†æä¾›çš„ prompt åˆ†ä¸ºä»¥ä¸‹å‡ ç§ä¿¡æ¯:\nImageï¼šæ¥è‡ª nuscenes æ•°æ®é›†ä¸­çš„ 6 ä¸ªæ‘„åƒå¤´ç”»é¢ï¼ŒæŒ‰ç…§å‰è§†å’Œåè§†åˆ’åˆ†è¿æ¥ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œimage prompt åœ¨ VQA ç”Ÿæˆæ—¶æ˜¯æ²¡æœ‰ä½¿ç”¨çš„ï¼Œè¿™ä¸€åšæ³•çŒœæµ‹å¯èƒ½æ˜¯é˜²æ­¢ GPT-4o çš„å¹»è§‰ï¼Œä¹Ÿå¯èƒ½ä»…ä»…æ˜¯å»¶ç»­ LLAVA ä¸­çš„åšæ³•ã€‚\nCaptionï¼šå¯¹é©¾é©¶åœºæ™¯çš„æ–‡æœ¬æè¿°ï¼Œå®é™…ä¸Šè¿™ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯å…ˆç”± GPTç”Ÿæˆçš„ï¼Œåç»­ä½œä¸ºç”Ÿæˆå…¶ä»–å†…å®¹çš„ promptã€‚ Lane-object associationï¼šåˆ©ç”¨ nuscenes æ•°æ®é›†ä¸­çš„æ£€æµ‹ä¿¡æ¯å’Œ lane å‡ ä½•ä¿¡æ¯åšåŒ¹é…ï¼Œå°†åŒ¹é…çš„ç»“æœä»¥ç›®å½•çš„å½¢å¼æä¾›ç»™ GPTï¼Œä¾¿äº GPT å¯¹æ•´ä¸ªé©¾é©¶åœºæ™¯ä¸­å„ lane æ„å»ºæ•´ä½“æ„ŸçŸ¥ã€‚ Simulated decision and trajectoryï¼šä½œè€…åŸºäºæ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼Œå°† nuscenes æ•°æ®é›†ä¸­æä¾›çš„ lane ä¸­å¿ƒçº¿è¿›è¡Œè¿æ¥ï¼Œå½¢æˆè½¨è¿¹ï¼Œç»è¿‡é€»è¾‘è¿‡æ»¤åï¼Œç”¨äºè®© GPT ç”Ÿæˆåäº‹å®æ¨æ–­ç›¸å…³çš„é—®ç­”ã€‚ Expert decision and trajectoryï¼šç›¸å¯¹äºä¸Šä¸€ä¸ªï¼Œè¿™é‡Œçš„â€œExpertâ€æ„ä¹‰ä¸º nuscenes ä¸­çš„çœŸå€¼è½¨è¿¹ä¿¡æ¯ï¼Œä»£è¡¨å®‰å…¨çš„é©¾é©¶è½¨è¿¹ï¼Œç”¨äºè®© GPT ç†è§£é©¾é©¶æ„å›¾å’Œå‡ ä½•åæ ‡ä¿¡æ¯ï¼ˆä½œè€…è¿™é‡Œçš„åæ ‡æ˜¯ 2d egoåæ ‡ç³»ï¼Œç¬¬ä¸€ç»´æ­£å€¼ä»£è¡¨å‰å‘ï¼Œç¬¬äºŒç»´æ­£å€¼ä»£è¡¨å·¦å‘ï¼‰ã€‚ ä»£ç è§£è¯» æ€»è§ˆï¼š\nç”¨åˆ°çš„æ•°æ®ç”Ÿæˆè„šæœ¬åˆ†ä¸ºä¸‰ä¸ªï¼š desc.pyï¼šå¯¹åº”ä¸Šå›¾ä¸­ caption çš„ç”Ÿæˆ conversation.py planning_vision.py é—®é¢˜ç­”æ¡ˆå¯¹ç”Ÿæˆé€»è¾‘ï¼Œå¯¹åº”transform_3d.pyæ–‡ä»¶ä¸­ä¸¤ä¸ªå‡½æ•°ï¼š preprocess_vqaï¼šå¯¹åº”ä¸Šå›¾ä¸­ Conversation çš„å†…å®¹ online_vqa 1. desc.py: ä»»åŠ¡æè¿°ï¼š promptä¸­æä¾›ç¯è§†å›¾åƒå’Œå½“å‰è½¦è¾†çš„è¡Œè½¦çŠ¶æ€ã€é©¾é©¶è¡Œä¸ºæè¿°ï¼ˆä¸“å®¶è½¨è¿¹ï¼‰ï¼Œéœ€è¦gptå®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼š\nåœ¨ä¸€æ®µè¯ä¸­æ€»ç»“é©¾é©¶åœºæ™¯ã€‚ -åœ¨æ­¤ä»»åŠ¡ä¸­ï¼Œåº”è¯¥æä¾›é©¾é©¶åœºæ™¯çš„è¯¦ç»†æè¿°ï¼Œä¾‹å¦‚æŒ‡å®šé“è·¯çŠ¶å†µã€‚ -æ³¨æ„ä»»ä½•ç‰¹å®šè®¾ç½®ï¼ˆåœè½¦åœºã€åå­—è·¯å£ã€ç¯å½¢äº¤å‰å£ï¼‰ã€äº¤é€šè¦ç´ ï¼ˆè¡Œäººã€è½¦è¾†ã€äº¤é€šæ ‡å¿—/ç¯ï¼‰ã€ä¸€å¤©ä¸­çš„æ—¶é—´å’Œå¤©æ°”ã€‚ åˆ†æå½“å‰é©¾é©¶è¡Œä¸ºã€‚ -ä»»åŠ¡æ˜¯ä½¿ç”¨ç»™å®šçš„å›¾åƒç®€è¦è§£é‡Šé©¾é©¶æ„å›¾ï¼Œå‡è®¾ä½ åœ¨çœŸå®åœºæ™¯ä¸­é©¾é©¶ã€‚ -æ‚¨åº”è¯¥äº†è§£æä¾›çš„å›¾åƒï¼Œé¦–å…ˆç¡®å®šæ­£ç¡®çš„é©¾é©¶å†³ç­–/æ„å›¾ï¼Œæ¨ç†å‡ºé©¾é©¶å‘˜åœ¨è¿™ç§æƒ…å†µä¸‹åº”è¯¥ç‰¹åˆ«æ³¨æ„çš„äº‹é¡¹ï¼Œå¹¶ä»¥è¦ç‚¹å½¢å¼åˆ—å‡ºã€‚ ä»£ç è§£è¯»ï¼š\nparser = argparse.ArgumentParser(description=\u0026#34;Process NuScenes data.\u0026#34;) parser.add_argument(\u0026#39;--base_path\u0026#39;, type=str, default=\u0026#39;data/nuscenes/\u0026#39;, help=\u0026#39;Base path to the NuScenes data.\u0026#39;) parser.add_argument(\u0026#39;--lane_info_path\u0026#39;, type=str, default=\u0026#39;data/nuscenes/data_dict_sample.pkl\u0026#39;, help=\u0026#39;Path to the lane info pickle file.\u0026#39;) parser.add_argument(\u0026#39;--info_file\u0026#39;, type=str, default=\u0026#39;data/nuscenes/nuscenes2d_ego_temporal_infos_train.pkl\u0026#39;, help=\u0026#39;Path to the info file (e.g., nuscenes2d_ego_temporal_infos_train.pkl).\u0026#39;) parser.add_argument(\u0026#39;--output_dir\u0026#39;, type=str, default=\u0026#39;./desc/train/\u0026#39;, help=\u0026#39;Directory to save the output JSON files.\u0026#39;) parser.add_argument(\u0026#39;--n_process\u0026#39;, type=int, default=8, help=\u0026#39;Number of processes to use.\u0026#39;) parser.add_argument(\u0026#39;--api_key\u0026#39;, type=str, required=True, help=\u0026#39;API key for OpenAI.\u0026#39;) è¿™é‡Œçš„base_pathæ˜¯nuscenesæ•°æ®é›†çš„å­˜æ”¾ç›®å½•\nlane_info_pathã€info_fileéƒ½æ˜¯ä½œè€…æä¾›çš„æ–‡ä»¶ï¼Œå…¶ä¸­ï¼š\nlane_info_pathå­˜æ”¾çš„æ˜¯openlane_v2æ•°æ®é›†ä¸­ï¼Œå„ä¸ªä¼ æ„Ÿå™¨çš„è·¯å¾„ã€å†…å¤–å‚ã€gtä¸­å„ä¸ªlaneã€traffic_elementä»¥åŠå®ƒä»¬ä¹‹é—´çš„æ‹“æ‰‘ç»“æ„ä¿¡æ¯ã€‚ info_fileå­˜æ”¾çš„æ˜¯nuscenseæ•°æ®ä¸­å„ä¸ªsceneä¸­æœ‰æ•ˆç›®æ ‡çš„ç›¸å…³ä¿¡æ¯ï¼Œ åŒ…æ‹¬lidaræ•°æ®å’Œcamæ•°æ®çš„å­˜æ”¾è·¯å¾„ã€gtçš„bboxä»¥åŠç±»åˆ«ä¿¡æ¯ç­‰ç­‰ æ¥ä¸‹æ¥æŒ‰info_fileä¸­çš„æ•°æ®ï¼Œåˆ†æˆå„ä¸ªtaskï¼š\ntasks = [(d, lane_infos, traj_gen, output_dir, api_key, sys_prompt) for d in data] # Call track_parallel_progress mmengine.track_parallel_progress( func=preprocess_single, tasks=tasks, nproc=n_process, keep_order=True, # Results will be in the order tasks were given ) å¤„ç†é€»è¾‘:\né¦–å…ˆä»info_fileæ‰¾åˆ°å¯¹åº”çš„lane_infoç´¢å¼•ä¿¡æ¯ï¼Œç„¶åä»lane_infoä¸­æ‹¿åˆ° ä¸­å¿ƒçº¿çš„pointsä½ç½®ä¿¡æ¯ï¼Œæ•°æ®æ ¼å¼[n_lane, 11, 3]ï¼ŒçŒœæµ‹æ˜¯æ¯æ¡laneéƒ½ç”±11ä¸ªå…³é”®ç‚¹åæ ‡æ¥è¡¨ç¤º gt_planning\\gt_planning_maskï¼ˆè¿™é‡Œçš„ç»´åº¦æ˜¯[n, 3], å‰ä¸¤ç»´æ˜¯åæ ‡ï¼Œåä¸€ç»´æ˜¯yawè§’ï¼‰ gt_fut_traj\\gt_fut_traj_maskï¼ˆæ˜¯æ¯ä¸€ä¸ªå‘¨å›´å…¶ä»–ç›®æ ‡çš„é¢„æµ‹è½¨è¿¹ï¼Œå¯ä»¥å’Œgtå¯¹åº”ä¸Šï¼‰ if \u0026#39;lane_info\u0026#39; in data.keys(): lane_info = lane_infos[data[\u0026#39;lane_info\u0026#39;]] lane_pts = [lane[\u0026#39;points\u0026#39;] for lane in lane_info[\u0026#39;annotation\u0026#39;][\u0026#39;lane_centerline\u0026#39;]] traj, mask = data[\u0026#39;gt_planning\u0026#39;][0], data[\u0026#39;gt_planning_mask\u0026#39;][0] gt_fut_traj, gt_fut_traj_mask = data[\u0026#39;gt_fut_traj\u0026#39;], data[\u0026#39;gt_fut_traj_mask\u0026#39;] planning_trajs, full_paths = traj_gen.generate_traj(lane_pts) expert_info = describe_expertv2(traj, mask, lane_pts, full_paths, gt_fut_traj, gt_fut_traj_mask, data[\u0026#39;gt_fullnames\u0026#39;], data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_attrs\u0026#39;]) æ¥ä¸‹æ¥è°ƒç”¨generate_trajå‡½æ•°ç”Ÿæˆè½¨è¿¹ï¼š\nåˆ©ç”¨å·²æœ‰çš„ä¸­å¿ƒçº¿pointåæ ‡ï¼Œä½¿ç”¨dfsç®—æ³•å’Œä¸€äº›è¿‡æ»¤é€»è¾‘ç”Ÿæˆæ‰€æœ‰å¯è¡Œçš„pathä»¥åŠpathä¸Šå…·ä½“çš„å…³é”®ç‚¹2ç»´åæ ‡ä¿¡æ¯\nåœ¨self.planning_anchorä¸­é¢„å®šä¹‰äº†300ä¸ªè½¨è¿¹ï¼Œæ¯æ¬¡ç”Ÿæˆè½¨è¿¹æ—¶ä¼šä»è¿™é‡Œé¢éšæœºæŒ‘é€‰ä¸‰ä¸ªå‡ºæ¥åŠ å…¥åˆ°å¤‡é€‰è½¨è¿¹ä¸­\nå¤‡é€‰è½¨è¿¹çš„ç”Ÿæˆæ˜¯å…ˆå¯¹ä¼ å…¥çš„all_path_ptsæ‹Ÿåˆä¸€ä¸ªæ›²çº¿ï¼Œè¿™é‡Œçš„è®¾ç½®æ˜¯ç”¨10ä¸ªç‚¹æ¥æ‹Ÿåˆï¼Œæ‰€ä»¥å¾—åˆ°çš„controj_pointsæ˜¯[10, 2]ï¼Œæ—¶é—´tè®¾ç½®çš„æ˜¯[6, 1]ã€ç„¶åè®¡ç®—yawè§’[6, 1]ã€è½¨è¿¹åæ ‡plan_traj[6, 2]ï¼Œreshapeä¸º[1, 12]ï¼Œæœ€ç»ˆçš„è½¨è¿¹è¡¨ç¤º æ ¼å¼ä¸º[1, 12 + 6 + 6]=[1, 24]\nå’Œä¹‹å‰éšæœºåŠ å…¥çš„è½¨è¿¹ä¸€èµ·ï¼Œéšæœºæ‰“ä¹±åæŒ‘é€‰å‡ºå‰5ä¸ªä½œä¸ºç»“æœè¿”å›\ndef generate_traj(self, lane_pts, max_traj=5): num_anchors = self.planning_anchor.shape[0] random_list = [random.randint(0, num_anchors-1) for _ in range(3)] all_paths_pts, full_paths = self.search_path(lane_pts) plan_trajs = [] for i in random_list: plan_trajs.append(self.planning_anchor[i].reshape(1, -1)) for path in all_paths_pts: t = self.generate_t(self.step) t = np.cumsum(t) controj_points = fit_bezier_Endpointfixed(path, 10) plan_yaw = bezier_tangent_angles(controj_points, t).reshape(-1, len(t)) plan_traj = control_points_to_lane_points(controj_points, t).numpy().reshape(-1, 2*len(t)) plan_trajs.append(np.concatenate([plan_traj, np.ones_like(plan_yaw), plan_yaw], -1)) random.shuffle(plan_trajs) plan_trajs = plan_trajs[:max_traj] return plan_trajs, full_paths è°ƒç”¨describe_expertv2å‡½æ•°ï¼Œä¸ºäº†å¾—åˆ°å½“å‰çŠ¶æ€çš„æè¿°ä¿¡æ¯ï¼š def describe_expertv2(gt_planning, planning_mask, lane_pts, full_paths, pred_traj, pred_traj_mask, names, bboxes, attrs): #nuscenesæ•°æ®é›†ä¸­çš„gtè½¨è¿¹ï¼Œå‰ä¸¤ç»´ä¸ºåæ ‡ï¼Œæœ€åä¸€ç»´æ˜¯yawè§’ planning_traj = gt_planning[..., :2] planning_yaw = gt_planning[..., 2] mask = planning_mask.any(axis=1) combined_data = list(zip(names, bboxes, attrs, pred_traj, pred_traj_mask)) #åˆçº§è¿‡æ»¤ï¼Œæ ¹æ®bboxçš„åæ ‡ï¼Œæ¨ªåæ ‡æˆ–è€…çºµåæ ‡å¤§äº50ï¼ˆè·ç¦»å¤ªè¿œï¼‰çš„ç›®æ ‡ç›´æ¥å»æ‰ filtered_data = [(name, bbox, attr, traj, traj_mask) for name, bbox, attr, traj, traj_mask in combined_data if abs(bbox[0]) \u0026lt;= 50 and abs(bbox[1]) \u0026lt;= 50] all_names = [] all_dists = [] all_xy = [] for name, bbox, attr, traj, traj_mask in filtered_data: if attr == \u0026#39;\u0026#39;: full_name = name else: attr = attr.split(\u0026#39;.\u0026#39;)[1] full_name = name + f\u0026#39;.{attr}\u0026#39; #ç´¯åŠ è½¨è¿¹å€¼ï¼Œè¡¨ç¤ºè¯¥ç‰©ä½“çš„ç›¸å¯¹åæ ‡ traj = np.cumsum(traj, axis=1) #å’Œè¯¥bboxä½ç½®ç›¸åŠ åå¯ä»¥å¾—åˆ°ç»å¯¹åæ ‡å€¼ traj += bbox[:2] masked_planning = gt_planning[mask] masked_traj = traj[traj_mask.astype(bool)][:6] #è®¡ç®—è¯¥ç›®æ ‡ç¦»è‡ªè½¦çš„è·ç¦» dist_rec = np.linalg.norm(bbox[:2]) if masked_planning.size == 0 or masked_traj.size == 0: l2_norm = dist_rec else: min_len = min(len(masked_planning), len(masked_traj)) l2_norm = np.linalg.norm(masked_planning[:min_len][..., :2] - masked_traj[:min_len], axis=1).min() #è®¡ç®—è¯¥ç›®æ ‡çš„è½¨è¿¹ä¸è‡ªè½¦è½¨è¿¹çš„æœ€å°è·ç¦»ï¼Œç”¨äºåˆ¤æ–­ä¸¤ä¸ªè½¨è¿¹æ˜¯å¦ç›¸å…³ dist = min(dist_rec, l2_norm) #å¦‚æœå°äº10ï¼Œå°±åŠ å…¥åˆ°å¤‡é€‰é¡¹ä¸­ if dist \u0026lt;= 10.0: all_names.append(full_name) all_dists.append(dist) all_xy.append(bbox[:2]) #å¾—åˆ°é€Ÿåº¦ï¼Œç”¨äºåˆ¤æ–­é€Ÿåº¦çŠ¶æ€ï¼š Stopped/Crawling/Moving slowly/Moderate speed/Moving fastly #åˆ©ç”¨çœŸå€¼è½¨è¿¹ï¼Œåˆ¤æ–­è½¦é“å˜æ¢è¡Œä¸ºï¼š Left Lane Changing/Right Lane Changing/Lane Keeping #æ ¹æ®yawè§’ï¼Œåˆ¤æ–­è¡Œè½¦è¡Œä¸ºï¼š Go Straight/Left U-turn/Right U-turn/Left Turn/Right Turn ego_vel = calculate_speed(planning_traj, mask) speed_state = judge_speed_changes(ego_vel[..., 0]) self_action = f\u0026#34;Expert decision: {speed_state}\u0026#34; lane_change = detect_lane_change(gt_planning[mask], lane_pts, full_paths) turning_behavior = determine_turning_behavior(planning_yaw) if speed_state not in [\u0026#34;Stopped\u0026#34;, \u0026#34;Unknown\u0026#34;]: if turning_behavior == \u0026#34;Go Straight\u0026#34;: self_action = self_action + \u0026#34;, \u0026#34; + lane_change if not (lane_change != \u0026#34;Lane Keeping\u0026#34; and turning_behavior == \u0026#34;Go Straight\u0026#34;): self_action = self_action + \u0026#34;, \u0026#34; + turning_behavior formatted_points = \u0026#39;, \u0026#39;.join(f\u0026#34;({format_number(point[0], 2)}, {format_number(point[1], 2)})\u0026#34; for point in planning_traj[mask]) self_traj = f\u0026#34;Expert trajectory: [PT, {formatted_points}].\u0026#34; ego_state = [self_action] #descriptionå¤§æ¦‚ç‡ä¼šç”±å½“å‰é€Ÿåº¦çŠ¶æ€ + å˜é“å€¾å‘/è½¬å¼¯å€¾å‘ æ„æˆ description = \u0026#39;\\n\u0026#39;.join(ego_state) return description æ¥ä¸‹æ¥å¤„ç†promptï¼š\nå°†å‰åå„ä¸‰å¼ å›¾ç‰‡æ‹¿åˆ°åè¿›è¡Œconcat + resizeæ“ä½œï¼Œä»[4800, 900] åˆ° [1536, 512]\nç„¶åå°†æ•°æ®æ ¼å¼å¤„ç†æˆBase64ï¼Œç”¨äºHTTPä¼ è¾“\nfront_image_paths = [data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT_LEFT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT_RIGHT\u0026#39;][\u0026#39;data_path\u0026#39;]] back_image_paths = [data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK_LEFT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK_RIGHT\u0026#39;][\u0026#39;data_path\u0026#39;]] front_image, back_image = create_combined_image(front_image_paths, back_image_paths) front_image = front_image.resize((1536, 512)) back_image = back_image.resize((1536, 512)) encoded_front_image = encode_image(front_image) encoded_back_image = encode_image(back_image) while True: try: hat_completion = client.chat.completions.create( model=\u0026#34;gpt-4o\u0026#34;, messages=[ **** ], temperature=0.7, top_p=0.7, max_tokens=2000, ) result = json.loads(replace_newlines_in_json_string(hat_completion.choices[0].message.content)) print(result) with open(output_file_path, \u0026#39;w\u0026#39;) as f: json.dump(result, f, indent=4) except Exception as e: print(e) else: break 2. conversation.py: ä»»åŠ¡æè¿°ï¼šåˆ©ç”¨ä¸Šä¸€æ­¥ä¸­ç”Ÿæˆçš„æè¿°ä¿¡æ¯ï¼Œç”Ÿæˆå¯¹åº”çš„å¯¹è¯é—®ç­”å†…å®¹ï¼Œä½†è¿™é‡Œè¿˜æ²¡æœ‰æ¶‰åŠåäº‹å®æ¨æ–­çš„ç”Ÿæˆï¼Œåªæ˜¯ä¸€äº›æ¯”è¾ƒç®€å•å®½æ³›çš„é—®ç­”ã€‚\nä»£ç è§£è¯»ï¼š\nè¿™é‡Œä¸å†éœ€è¦ä¼ å…¥laneæœ‰å…³çš„ä¿¡æ¯ï¼Œè€Œæ˜¯éœ€è¦æ‹¿åˆ°ä¸Šä¸€æ­¥è„šæœ¬ä¸­ç”Ÿæˆçš„descæ–‡æœ¬ã€‚\nparser = argparse.ArgumentParser(description=\u0026#34;Process NuScenes data.\u0026#34;) parser.add_argument(\u0026#39;--info_file\u0026#39;, type=str, default=\u0026#39;data/nuscenes/nuscenes2d_ego_temporal_infos_train.pkl\u0026#39;, help=\u0026#39;Path to the info file (e.g., nuscenes2d_ego_temporal_infos_train.pkl).\u0026#39;) parser.add_argument(\u0026#39;--desc_path\u0026#39;, type=str, default=\u0026#39;./desc/train/\u0026#39;, help=\u0026#39;Path to the description files directory.\u0026#39;) parser.add_argument(\u0026#39;--output_dir\u0026#39;, type=str, default=\u0026#39;./conv/train/\u0026#39;, help=\u0026#39;Directory to save the output JSON files.\u0026#39;) parser.add_argument(\u0026#39;--n_process\u0026#39;, type=int, default=8, help=\u0026#39;Number of processes to use.\u0026#39;) parser.add_argument(\u0026#39;--api_key\u0026#39;, type=str, required=True, help=\u0026#39;API key for OpenAI.\u0026#39;) args = parser.parse_args() main(args.info_file, args.desc_path, args.output_dir, args.n_process, args.api_key) æ¥ä¸‹æ¥å°±ç›´æ¥åˆ©ç”¨å·²æœ‰ä¿¡æ¯æ¥ç”Ÿæˆpromptï¼š\né¦–å…ˆä¼ å…¥çš„æ˜¯descæ–‡æœ¬ä¸­çš„descriptionå’Œactionä¸¤ä¸ªtextï¼› ç„¶åæ˜¯ä¸¤ä¸ªæ‹¼æ¥åçš„å‰åå›¾åƒï¼› ä»»åŠ¡ï¼š åˆ†æå’Œè§£é‡Šå½“å‰çš„é©¾é©¶è¡Œä¸ºå’Œç›¸å…³çš„é©¾é©¶åœºæ™¯ï¼Œè®¾è®¡ä¸€ä¸ªä½ å’Œä¸€ä¸ªäººä¹‹é—´çš„å¯¹è¯ï¼Œè¯¢é—®è¿™ä¸ªé©¾é©¶åœºæ™¯ã€‚æå‡ºä¸åŒçš„é—®é¢˜å¹¶ç»™å‡ºç›¸åº”çš„ç­”æ¡ˆã€‚ä¸è¦é—®ä»»ä½•ä¸èƒ½ç¡®å®šå›ç­”çš„é—®é¢˜ã€‚ è¿˜åŒ…æ‹¬ä¸å›¾åƒä¸­çš„å†…å®¹ç›¸å…³çš„å¤æ‚é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œè¯¢é—®åœºæ™¯ä¸­å¯¹è±¡çš„èƒŒæ™¯çŸ¥è¯†ï¼Œè¦æ±‚è®¨è®ºåœºæ™¯ä¸­å‘ç”Ÿçš„äº‹ä»¶ã€‚åœ¨å›ç­”å¤æ‚é—®é¢˜æ—¶æä¾›è¯¦ç»†çš„ç­”æ¡ˆã€‚ä¾‹å¦‚ï¼Œç»™å‡ºè¯¦ç»†çš„ä¾‹å­æˆ–æ¨ç†æ­¥éª¤ï¼Œä½¿å†…å®¹æ›´å…·è¯´æœåŠ›å’Œç»„ç»‡æ€§ã€‚ output_file_path = osp.join(output_dir, data[\u0026#39;token\u0026#39;] + \u0026#34;.json\u0026#34;) os.makedirs(osp.dirname(output_file_path), exist_ok=True) if not osp.isfile(osp.join(output_dir, data[\u0026#39;token\u0026#39;]+\u0026#39;.json\u0026#39;)): with open(osp.join(desc_path, data[\u0026#39;token\u0026#39;] + \u0026#34;.json\u0026#34;), \u0026#39;r\u0026#39;) as f: scene_keywords = json.load(f) user_prompt = f\u0026#34;\u0026#34;\u0026#34; Description: {scene_keywords[\u0026#34;description\u0026#34;]} Action: {scene_keywords[\u0026#34;action\u0026#34;]} \u0026#34;\u0026#34;\u0026#34; front_image_paths = [data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT_LEFT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_FRONT_RIGHT\u0026#39;][\u0026#39;data_path\u0026#39;]] back_image_paths = [data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK_LEFT\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK\u0026#39;][\u0026#39;data_path\u0026#39;], data[\u0026#39;cams\u0026#39;][\u0026#39;CAM_BACK_RIGHT\u0026#39;][\u0026#39;data_path\u0026#39;]] front_image, back_image = create_combined_image(front_image_paths, back_image_paths) front_image = front_image.resize((1536, 512)) back_image = back_image.resize((1536, 512)) encoded_front_image = encode_image(front_image) encoded_back_image = encode_image(back_image) while True: try: hat_completion = client.chat.completions.create( model=\u0026#34;gpt-4o\u0026#34;, messages=[ ****** ], temperature=0.9, top_p=0.7, max_tokens=2000, ) result = json.loads(replace_newlines_in_json_string(hat_completion.choices[0].message.content)) with open(osp.join(output_dir, data[\u0026#39;token\u0026#39;]+\u0026#39;.json\u0026#39;), \u0026#39;w\u0026#39;) as f: json.dump(result, f, indent=4) except Exception as e: print(e) continue else: break 3. prompt_vision.py: ä»»åŠ¡æè¿°ï¼šè¿™æ¬¡å’Œå‰ä¸¤ä¸ªè„šæœ¬æœ‰ä¸€ä¸ªæ˜æ˜¾çš„ä¸åŒåœ¨äºï¼šæ²¡æœ‰æä¾›ç»™æ¨¡å‹imageä½œä¸ºä¿¡æ¯ï¼Œåªæä¾›äº†å„ç§æ–‡æœ¬å½¢å¼çš„æè¿°ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¨¡æ‹Ÿè½¨è¿¹å’Œä¸“å®¶è½¨è¿¹ï¼Œä»¥åŠè½¦é“å’Œç›®æ ‡çš„å…³è”ä¿¡æ¯ï¼Œç”¨äºç”ŸæˆåŒ…æ‹¬åäº‹å®æ¨æ–­çš„å¤æ‚é—®ç­”ã€‚\nå‡†å¤‡çš„promptå†…å®¹åŒ…æ‹¬ï¼š\nScene Infoï¼šç›®å½•ç»“æ„çš„è½¦é“çº¿ï¼Œä»¥åŠè½¦é“çº¿ä¸Šéœ€è¦æ³¨æ„çš„ç‰©ä½“ç±»åˆ«ã€åæ ‡ä¿¡æ¯\nScene keywordsï¼šdesc.pyç”Ÿæˆçš„description å’Œ action\nPlanning infoï¼šå½“å‰çœŸå€¼è½¨è¿¹å¯¹åº”çš„çŠ¶æ€ã€é©¾é©¶æŒ‡ä»¤ä¿¡æ¯ï¼Œè¿˜åŒ…æ‹¬è½¨è¿¹ä¸Šå…¶ä»–éœ€è¦æ³¨æ„çš„ç›®æ ‡çš„åæ ‡ä¿¡æ¯\nSimulated infoï¼šç”Ÿæˆçš„å¤šä¸ªæ¨¡æ‹Ÿè½¨è¿¹å¯¹åº”çš„çŠ¶æ€ã€æŒ‡ä»¤ï¼Œä»¥åŠå…·ä½“çš„è½¨è¿¹åæ ‡ï¼Œå’Œè¯¥è½¨è¿¹å¯¹åº”çš„è¯­ä¹‰çœŸå€¼ä¿¡æ¯ï¼šæ˜¯å¦å®‰å…¨ï¼Œ\nsys_prompt: å‘Šè¯‰gptä»¥ä¸Šä¿¡æ¯çš„å¯¹åº”æ„ä¹‰ï¼Œä»¥åŠéœ€è¦gptå®Œæˆçš„ä»»åŠ¡ï¼š\nâ€‹ è®¾è®¡4ä¸ªå…³äºå½“å‰é©¾é©¶åœºæ™¯çš„é—®ç­”å¯¹ã€‚\næé—®å¤šæ ·åŒ–ï¼Œæ”¹å†™ä»¥ä¸‹é—®é¢˜ä¸ºæ›´è‡ªç„¶çš„è¡¨è¿°ï¼Œå¹¶ç»™å‡ºè¯¦ç»†ç­”æ¡ˆï¼ŒåŒ…æ‹¬åŸºäºå½“å‰è¾“å…¥è§‚å¯Ÿçš„æ•°å€¼ä¿¡æ¯ã€‚\nâ€‹ é—®é¢˜ç¤ºä¾‹ï¼š\nQ1: æ˜¯å¦å­˜åœ¨å¯èƒ½å½±å“æ‚¨é©¾é©¶è¡Œä¸ºçš„äº¤é€šå…ƒç´ ï¼Ÿå¦‚æœæœ‰ï¼Œå®ƒä»¬æ˜¯ä»€ä¹ˆï¼Ÿ\nQ2: æ‚¨çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\nå‚è€ƒä¸“å®¶/ç¤ºä¾‹è½¨è¿¹è®¾è®¡ä¸¤ä¸ªç±»ä¼¼çš„é—®é¢˜ï¼š\nQ3: å¦‚æœæ‚¨éµå¾ªè½¨è¿¹ [PT, (x1, y1), (x2, y2), (x3, y3)] [åœ¨æ­¤å¤„æ›¿æ¢ä¸ºç¤ºä¾‹è½¨è¿¹]ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ Q4ï¼šâ€¦â€¦ ä»£ç é€»è¾‘ï¼š\nä¼ å…¥å‚æ•°ï¼š\næ•°æ®é›†æœ‰å…³ä¿¡æ¯nuscenes_info_file data_dict_file æ ‘å½¢ç»“æ„çš„é“è·¯ä¿¡æ¯ desc_path descæ–‡ä»¶å­˜æ”¾ç›®å½• parser = argparse.ArgumentParser(description=\u0026#34;Process driving scenarios and generate QA pairs.\u0026#34;) parser.add_argument(\u0026#39;--base_path\u0026#39;, type=str, default=\u0026#39;./data/nuscenes/\u0026#39;, help=\u0026#39;Base path to the data directory.\u0026#39;) parser.add_argument(\u0026#39;--nuscenes_info_file\u0026#39;, type=str, default=\u0026#39;nuscenes2d_ego_temporal_infos_train.pkl\u0026#39;, help=\u0026#39;Nuscenes info file.\u0026#39;) parser.add_argument(\u0026#39;--data_dict_file\u0026#39;, type=str, default=\u0026#39;data_dict_sample.pkl\u0026#39;, help=\u0026#39;Data dictionary file.\u0026#39;) parser.add_argument(\u0026#39;--output_dir\u0026#39;, type=str, default=\u0026#39;./vqa/train\u0026#39;, help=\u0026#39;Output directory for results.\u0026#39;) parser.add_argument(\u0026#39;--desc_path\u0026#39;, type=str, default=\u0026#39;./desc/train/\u0026#39;, help=\u0026#39;Path to the description files directory.\u0026#39;) parser.add_argument(\u0026#39;--api_key\u0026#39;, type=str, required=True, help=\u0026#39;API key for OpenAI.\u0026#39;) parser.add_argument(\u0026#39;--n_process\u0026#39;, type=int, default=8, help=\u0026#39;Number of parallel processes to use.\u0026#39;) args = parser.parse_args() ä¸»è¦è°ƒç”¨å‡½æ•°åŒ…æ‹¬ï¼š\nå¤„ç†äººè¡Œæ–‘é©¬çº¿ get_crosswalkså‡½æ•°ï¼Œä¸»è¦é€»è¾‘æ˜¯å°†æ–‘é©¬çº¿åŒºåŸŸè½¬æ¢ä¸ºå‡ ä½•çŸ©å½¢è¡¨ç¤ºï¼› generate_trajå‡½æ•°ï¼šå’Œdescæ–‡ä»¶ä¸­ä¸€æ ·é€šè¿‡dfså¾—åˆ°ä¸åŒçš„å¯è¡Œè½¨è¿¹ scene_descriptionå‡½æ•°ï¼šæ ¹æ®å·²æœ‰çš„å„ç§é“è·¯ç›®æ ‡ç”Ÿæˆä¸€ä¸ªç›®å½•å¼çš„ç»“æ„ï¼ŒåŒ…å«crosswalkã€laneå’Œå¯¹åº”obj describe_expertå‡½æ•°ï¼šå¯¹çœŸå€¼è½¨è¿¹ç”Ÿæˆä¸€ä¸ªæè¿°ï¼Œä»¥åŠå…¶éœ€è¦æ³¨æ„çš„objç±»åˆ«ã€åæ ‡ç­‰ä¿¡æ¯ gt_fut_traj, gt_fut_traj_mask = data[\u0026#39;gt_fut_traj\u0026#39;], data[\u0026#39;gt_fut_traj_mask\u0026#39;] crosswalks = get_crosswalks(data[\u0026#39;map_geoms\u0026#39;]) planning_trajs, full_paths = traj_gen.generate_traj(lane_pts) scene_info, lanes_red = scene_description(traj, mask, lane_info, data[\u0026#39;gt_fullnames\u0026#39;], data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_velocity\u0026#39;], data[\u0026#39;gt_attrs\u0026#39;], lane_pts, crosswalks) expert_info = describe_expert(traj, mask, lane_pts, full_paths, gt_fut_traj, gt_fut_traj_mask, data[\u0026#39;gt_fullnames\u0026#39;], data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_attrs\u0026#39;]) scene_descriptionå‡½æ•°ï¼š\ndef scene_description(gt_planning, planning_mask, lane_info, objects_list, bboxes, velocity, attrs, lane_pts, crosswalks): output_lines = [] #æ ¹æ®lane_infoä¸­çš„traffic_elementä¿¡æ¯ï¼Œæ¥åˆ¤æ–­æ˜¯å¦æœ‰äº¤é€šç¯å­˜åœ¨ï¼Œç”Ÿæˆå¯¹åº”çš„æ–‡æœ¬ï¼šTraffic Light Existing: False|True tl_description = describe_tl(lane_info) output_lines.append(tl_description) #å¾—åˆ°æ‰€æœ‰è½¦é“çš„descriptionåŒ…å«æ–¹å‘ã€å…·ä½“çš„pointåæ ‡å’Œç›¸å…³äº¤é€šå…ƒç´ çš„åˆ†ç±»ï¼Œå’Œçº¢ç¯å¯¹åº”è½¦é“çš„ä¿¡æ¯ lane_description, lanes_red = describe_lanes(lane_info) #å¾—åˆ°crosswalkçš„åæ ‡æè¿° crosswalk_description = describe_crosswalks(crosswalks) #å°†äº¤é€šå‚ä¸è€…ä¸è½¦é“å’Œæ–‘é©¬çº¿å…³è” lane_objects, crosswalk_objects = describe_objects2lane(gt_planning, planning_mask, objects_list, bboxes, velocity, attrs, lane_pts, crosswalks) if len(objects_list) == 0: output_lines.append(f\u0026#34;No traffic participants observed in the scene.\u0026#34;) #åœ¨lane_objectsä¸­åŠ å…¥è‡ªè½¦çš„ä¿¡æ¯ï¼Œego_indexè¡¨ç¤ºè‡ªè½¦æ‰€åœ¨çš„è½¦é“index lane_objects, ego_index = add_ego2lane(gt_planning, planning_mask, lane_pts, lane_objects) #åˆ©ç”¨ä»¥ä¸Šçš„ä¿¡æ¯æ¥æ„æˆæœ€ç»ˆè¾“å‡ºçš„description_scene,è¿”å›çš„æ˜¯è®ºæ–‡ä¸­æ‰€è¯´çš„æ ‘å½¢ç»“æ„çš„æ•°æ® for i, crosswalk_desc in enumerate(crosswalk_description): output_lines.append(f\u0026#34;â”œâ”€â”€ {crosswalk_desc}\u0026#34;) if i in crosswalk_objects.keys(): for obj_desc in crosswalk_objects[i]: output_lines.append(f\u0026#34;â”‚ â”œâ”€â”€ {obj_desc}\u0026#34;) for i, lane_desc in enumerate (lane_description): if i == ego_index: lane_desc = lane_desc.replace(\u0026#34;with-flow, \u0026#34;, \u0026#34;your current \u0026#34;) output_lines.append(f\u0026#34;â”œâ”€â”€ {lane_desc}\u0026#34;) if i in lane_objects.keys(): for obj_desc in lane_objects[i]: output_lines.append(f\u0026#34;â”‚ â”œâ”€â”€ {obj_desc}\u0026#34;) if \u0026#39;others\u0026#39; in lane_objects: output_lines.append(\u0026#34;â”œâ”€â”€ Other Lanes/Roadside\u0026#34;) for obj_desc in lane_objects[\u0026#39;others\u0026#39;]: output_lines.append(f\u0026#34;â”‚ â”œâ”€â”€ {obj_desc}\u0026#34;) return \u0026#39;\\n\u0026#39;.join(output_lines), lanes_red describe_expertå‡½æ•°ï¼ˆå¤§éƒ¨åˆ†é€»è¾‘éƒ½å’Œv2ç›¸åŒï¼Œä¸åŒä¹‹å¤„åœ¨äºï¼šæœ€ååŠ å…¥äº†ä¸å½“å‰è½¨è¿¹å¯èƒ½æœ‰ç›¸äº¤çš„ç›®æ ‡çš„ç±»åˆ«å’Œåæ ‡ä¿¡æ¯ï¼‰ï¼š\ndef describe_expert(gt_planning, planning_mask, lane_pts, full_paths, pred_traj, pred_traj_mask, names, bboxes, attrs): planning_traj = gt_planning[..., :2] planning_yaw = gt_planning[..., 2] mask = planning_mask.any(axis=1) combined_data = list(zip(names, bboxes, attrs, pred_traj, pred_traj_mask)) filtered_data = [(name, bbox, attr, traj, traj_mask) for name, bbox, attr, traj, traj_mask in combined_data if abs(bbox[0]) \u0026lt;= 50 and abs(bbox[1]) \u0026lt;= 50] all_names = [] all_dists = [] all_xy = [] for name, bbox, attr, traj, traj_mask in filtered_data: if attr == \u0026#39;\u0026#39;: full_name = name else: attr = attr.split(\u0026#39;.\u0026#39;)[1] full_name = name + f\u0026#39;.{attr}\u0026#39; traj = np.cumsum(traj, axis=1) traj += bbox[:2] masked_planning = gt_planning[mask] masked_traj = traj[traj_mask.astype(bool)][:6] dist_rec = np.linalg.norm(bbox[:2]) # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºæ•°ç»„ï¼Œå¦‚æœæœ‰ï¼Œåˆ™ä¸èƒ½è®¡ç®—è·ç¦» if masked_planning.size == 0 or masked_traj.size == 0: l2_norm = dist_rec else: # è‹¥ä¸¤æ•°ç»„é•¿åº¦ä¸åŒï¼Œå–è¾ƒå°çš„é•¿åº¦æ¥è®¡ç®—L2 Norm min_len = min(len(masked_planning), len(masked_traj)) # è®¡ç®—L2 Norm l2_norm = np.linalg.norm(masked_planning[:min_len][..., :2] - masked_traj[:min_len], axis=1).min() dist = min(dist_rec, l2_norm) if dist \u0026lt;= 10.0: all_names.append(full_name) all_dists.append(dist) all_xy.append(bbox[:2]) ego_vel = calculate_speed(planning_traj, mask) speed_state = judge_speed_changes(ego_vel[..., 0]) self_action = f\u0026#34;Expert decision: {speed_state}\u0026#34; lane_change = detect_lane_change(gt_planning[mask], lane_pts, full_paths) turning_behavior = determine_turning_behavior(planning_yaw) if speed_state not in [\u0026#34;Stopped\u0026#34;, \u0026#34;Unknown\u0026#34;]: if turning_behavior == \u0026#34;Go Straight\u0026#34;: self_action = self_action + \u0026#34;, \u0026#34; + lane_change if not (lane_change != \u0026#34;Lane Keeping\u0026#34; and turning_behavior == \u0026#34;Go Straight\u0026#34;): self_action = self_action + \u0026#34;, \u0026#34; + turning_behavior formatted_points = \u0026#39;, \u0026#39;.join(f\u0026#34;({format_number(point[0], 2)}, {format_number(point[1], 2)})\u0026#34; for point in planning_traj[mask]) self_traj = f\u0026#34;Expert trajectory: [PT, {formatted_points}].\u0026#34; ego_state = [self_action, self_traj] description = \u0026#39;\\n\u0026#39;.join(ego_state) if len(all_dists): desc_near = f\u0026#34;Objects near your path: \u0026#34; for i, obj in enumerate(all_names): desc_near += f\u0026#34;{all_names[i]} at ({format_number(all_xy[i][0])}, {format_number(all_xy[i][1])})\u0026#34; if i != len(all_dists) -1: desc_near += \u0026#34;, \u0026#34; else: desc_near += \u0026#34;.\u0026#34; description = description + \u0026#34;\\n\u0026#34; + desc_near return description è¿è¡Œå®Œä»¥ä¸Šä¸¤ä¸ªå‡½æ•°ä»¥åï¼Œæ¥ä¸‹æ¥ç»§ç»­å¤„ç†ï¼š\ngt_fut_traj, gt_fut_traj_mask = data[\u0026#39;gt_fut_traj\u0026#39;], data[\u0026#39;gt_fut_traj_mask\u0026#39;] crosswalks = get_crosswalks(data[\u0026#39;map_geoms\u0026#39;]) planning_trajs, full_paths = traj_gen.generate_traj(lane_pts) scene_info, lanes_red = scene_description(traj, mask, lane_info, data[\u0026#39;gt_fullnames\u0026#39;], data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_velocity\u0026#39;], data[\u0026#39;gt_attrs\u0026#39;], lane_pts, crosswalks) expert_info = describe_expert(traj, mask, lane_pts, full_paths, gt_fut_traj, gt_fut_traj_mask, data[\u0026#39;gt_fullnames\u0026#39;], data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_attrs\u0026#39;]) ego_boxes = np.array([[1.5, 0.0, 0.0, 4.08, 1.73, 0.0, 0.0, 0.0, 0.0]]) step = 6 light_seg = planning_metric.red_light_area(lanes_red) gt_agent_boxes = np.concatenate([data[\u0026#39;gt_boxes\u0026#39;], data[\u0026#39;gt_velocity\u0026#39;]], -1) gt_agent_feats = np.concatenate([data[\u0026#39;gt_fut_traj\u0026#39;][:, :6].reshape(-1, 12), data[\u0026#39;gt_fut_traj_mask\u0026#39;][:, :6], data[\u0026#39;gt_fut_yaw\u0026#39;][:, :6], data[\u0026#39;gt_fut_idx\u0026#39;]], -1) bev_seg = planning_metric.get_birds_eye_view_label(gt_agent_boxes, gt_agent_feats) e2g_r_mat = Quaternion(data[\u0026#39;ego2global_rotation\u0026#39;]).rotation_matrix e2g_t = data[\u0026#39;ego2global_translation\u0026#39;] drivable_seg = planning_metric.get_drivable_area(e2g_t, e2g_r_mat, data) all_coll_objs = [] all_red_lights = [] all_drivable = [] for traj in planning_trajs: ego_seg = planning_metric.get_ego_seg(ego_boxes, traj, add_rec=True) coll_index, red_light, out_of_drivable = planning_metric.traj_check(ego_seg, bev_seg, light_seg, drivable_seg) all_red_lights.append(red_light) all_drivable.append(out_of_drivable) coll_obj = [(data[\u0026#39;gt_fullnames\u0026#39;][idx], data[\u0026#39;gt_attrs\u0026#39;][idx], data[\u0026#39;gt_boxes\u0026#39;][idx]) for idx in coll_index] all_coll_objs.append(coll_obj) #describe_simulatedå‡½æ•°ä¸»è¦æ˜¯æ ¹æ®ä¸Šè¿°çš„ä¿¡æ¯ï¼Œå¯¹æ¯æ¡æ¨¡æ‹Ÿè½¨è¿¹åšåˆ¤æ–­ï¼Œå¾—åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š #è‡ªè½¦çš„è½¨è¿¹å’Œè¡Œä¸ºåˆ†æã€‚ #æ˜¯å¦é—¯çº¢ç¯ã€‚ #æ˜¯å¦é©¶å‡ºå¯è¡Œé©¶åŒºåŸŸã€‚ #æ˜¯å¦ä¸å…¶ä»–å¯¹è±¡å‘ç”Ÿç¢°æ’ã€‚ #ç»¼åˆç”Ÿæˆæ¯æ¡è½¨è¿¹çš„å†³ç­–å’Œå®‰å…¨æ€§è¯„ä»·ã€‚ simulated_info = describe_simulated(step, planning_trajs, lane_pts, all_coll_objs, all_red_lights, all_drivable, full_paths) area = data[\u0026#39;location\u0026#39;].split(\u0026#34;-\u0026#34;)[0] sys_prompt = make_context(area, side) 4. preprocess_vqaå‡½æ•°ï¼š ä»»åŠ¡æè¿°ï¼šè¯»å–å‰é¢ç”Ÿæˆçš„descã€convã€vqaæ–‡ä»¶ï¼Œå°†å…¶ä¸­çš„å†…å®¹å¤„ç†æˆèƒ½è¾“å…¥ç»™å¤§è¯­è¨€æ¨¡å‹çš„æ ¼å¼ã€‚\nkeywordï¼šä»é€»è¾‘å¤§æ¦‚çœ‹å¾—å‡ºæ¥ï¼Œkeywordæ˜¯gptå¯¹å½“å‰é©¾é©¶è¡Œä¸ºçš„ç®€å•æè¿°ï¼Œä½†æ–‡æœ¬æ˜¯ä½œè€…ç›´æ¥æä¾›çš„ï¼Œå¹¶æ²¡æœ‰ç›¸åº”çš„ç”Ÿæˆé€»è¾‘è„šæœ¬ã€‚\nif os.path.exists(self.base_key_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;): with open(self.base_key_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;, \u0026#39;r\u0026#39;) as f: action = json.load(f) sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: \u0026#34;Please shortly describe your driving action.\u0026#34;}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: action} ] ) descï¼šè¿™é‡Œæ˜¯ä»å·²æœ‰çš„10ä¸ªé—®é¢˜æ¨¡æ¿ä¸­éšæœºé€‰ä¸€ä¸ªä½œä¸ºé—®é¢˜ï¼Œç„¶åå°†descä¸­çš„æè¿°éƒ¨åˆ†ä½œä¸ºè¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆç”¨äºç›‘ç£æ¨¡å‹ï¼š\nself.template = [ \u0026#34;What can you tell about the current driving conditions from the images?\u0026#34;, \u0026#34;What can be observed in the panoramic images provided?\u0026#34;, \u0026#34;Can you provide a summary of the current driving scenario based on the input images?\u0026#34;, \u0026#34;What can you observe from the provided images regarding the driving conditions?\u0026#34;, \u0026#34;Please describe the current driving conditions based on the images provided.\u0026#34;, \u0026#34;Can you describe the current weather conditions and the general environment depicted in the images?\u0026#34;, \u0026#34;Please describe the current driving conditions based on the input images.\u0026#34;, \u0026#34;Could you summarize the current driving conditions based on the input images?\u0026#34;, \u0026#34;Please provide an overview of the current driving conditions based on the images.\u0026#34;, \u0026#34;Can you summarize what the panoramic images show?\u0026#34;, \u0026#34;Can you describe the overall conditions and environment based on the images?\u0026#34;, \u0026#34;Could you describe the overall environment and objects captured in the images provided?\u0026#34; ] if os.path.exists(self.base_desc_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;): with open(self.base_desc_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;, \u0026#39;r\u0026#39;) as f: desc = json.load(f) question = random.sample(self.template, 1)[0] sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: question}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: desc[\u0026#34;description\u0026#34;]} ] ) convå’Œvqaéƒ½æ˜¯ä¸€æ ·çš„å¤„ç†æ–¹å¼ï¼Œè¯»å–é—®é¢˜å’Œç­”æ¡ˆï¼š\nif os.path.exists(self.base_vqa_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;): with open(self.base_vqa_path+results[\u0026#39;sample_idx\u0026#39;]+\u0026#34;.json\u0026#34;, \u0026#39;r\u0026#39;) as f: data_qa = json.load(f) for i, pair in enumerate(data_qa): sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: pair[\u0026#34;question\u0026#34;]}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: pair[\u0026#34;answer\u0026#34;]} ] ) 5. online_vqaå‡½æ•°ï¼š ä»»åŠ¡æè¿°ï¼š é€šè¿‡è¯»å–nuscenseä¸­çš„æœ‰å…³ä¿¡æ¯ï¼Œç”Ÿæˆå¸¦åæ ‡ä¿¡æ¯çš„åœ¨çº¿é—®ç­”é—®é¢˜ï¼š\n2d bboxç‰©ä½“æé—®ï¼š if len(gt_bboxes_2d) \u0026gt;= 1: selected_objs = random.sample(gt_bboxes_2d, min(self.n_gen, len(gt_bboxes_2d))) for obj in selected_objs: answer = self.format_det_answer(obj[4], gt_bboxes_3d, results) sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;Please Identity the object in the \u0026lt;{obj[5]}, {obj[0]}, {obj[1]}, {obj[2]}, {obj[3]}\u0026gt; and describe its 3D information.\u0026#34;}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;The object is a {answer}\u0026#34;,} ] ) 3dåæ ‡ä½ç½®å‘¨å›´ç‰©ä½“æé—®ï¼š sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;What objects are there near the position ({format_number(center[0].item())}, {format_number(center[1].item())})?\u0026#34;}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;{answer}\u0026#34;,} ] ) è½¦é“çº¿laneæé—®ï¼š for idx in index_list: if idx not in lane_objs[\u0026#39;lane_objects\u0026#39;].keys(): sources.append( [ {\u0026#34;from\u0026#34;: \u0026#39;human\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;What objects are there on the lane {self.describe_lane([lane_objs[\u0026#39;all_lane_pts\u0026#39;][idx]])}?\u0026#34;}, {\u0026#34;from\u0026#34;: \u0026#39;gpt\u0026#39;, \u0026#34;value\u0026#34;: f\u0026#34;The objects on this lane include:\\n{answer}\u0026#34;,} ] ) ","permalink":"https://ouhaoten.github.io/posts/2024-12-15-omnidrive/","summary":"\u003ch1 id=\"ä¸€è®ºæ–‡æ€»è§ˆ\"\u003eä¸€.è®ºæ–‡æ€»è§ˆ\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://picgo-1301748200.cos.ap-chengdu.myqcloud.com/image-20241214214025876-20241215112414825.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"é—®é¢˜èƒŒæ™¯\"\u003eé—®é¢˜èƒŒæ™¯ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eç°æœ‰çš„å°†å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMultimodal Large Language Model, MLLMï¼‰å¼•å…¥è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„æ–¹æ³•ä¸­ï¼Œå¤§å¤šä¸å…·å¤‡3Dåœºæ™¯ç†è§£èƒ½åŠ›ï¼Œä½†è¿™ä¸€èƒ½åŠ›å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯è€Œè¨€æ˜¯ä¸å¯æˆ–ç¼ºçš„ï¼Œä»¥ä¸€ä¸ªé©¾é©¶åœºæ™¯ä¸­å¸¸è§çš„é—®é¢˜ä¸ºä¾‹ï¼šâ€œè¯¢é—®å½“å‰è½¦é“æ˜¯å¦å¯ä»¥å·¦è½¬â€ï¼Œè¯¥é—®é¢˜çœ‹ä¼¼åœ¨åšä¸€ä¸ªç®€å•çš„è¯­ä¹‰åˆ¤æ–­ï¼Œæœ¬è´¨ä¸Šéœ€è¦æ¶‰åŠåˆ°å¯¹è½¦é“ä¸è‡ªè½¦çš„å‡ ä½•å…³ç³»åˆ¤æ–­ã€è½¦é“ä¸äº¤é€šç¯è¯­ä¹‰ã€åœ°é¢æ ‡è¯†è¯­ä¹‰çš„åŒ¹é…ï¼Œè¦å›ç­”è¿™äº›é—®é¢˜ï¼Œéœ€è¦ MLLM æ¨¡å‹å°† 2D ç†è§£å’Œæ¨ç†èƒ½åŠ›æ‰©å±•åˆ°å¤æ‚çš„ 3Dåœºæ™¯ä¸­ã€‚\u003c/li\u003e\n\u003cli\u003eç°æœ‰ MLLM æ¨¡å‹æŒ‰ç…§å¯¹å›¾åƒçš„å¤„ç†æ–¹å¼çš„ä¸åŒï¼Œå¯ä»¥åˆ†ä¸ºä¸¤ç§æµæ´¾ï¼šä¸€ç§æ˜¯ä»¥ Flamingo ã€BLIP-2ã€Qwenç­‰æ–¹æ³•ä¸ºä»£è¡¨ï¼Œä»¥äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¸ºåŸºç¡€ï¼Œç‰¹ç‚¹æ˜¯ä¸è®ºå›¾åƒåˆ†è¾¨ç‡éƒ½å¤„ç†æˆç»Ÿä¸€é•¿åº¦çš„ token åºåˆ—ï¼Œè€Œå¦ä¸€ç§æ˜¯ä»¥ Vitã€ BLIPã€LLAVA ä¸ºä»£è¡¨ï¼Œä»¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸ºåŸºç¡€ï¼Œæ¯ä¸ª token ç”¨äºä»£è¡¨å›ºå®šåƒç´ å¤§å°çš„å›¾åƒå±€éƒ¨ä¿¡æ¯ï¼Œè¿™æ„å‘³ç€ä¸åŒçš„åˆ†è¾¨ç‡å›¾åƒå¯¹åº”å˜é•¿çš„ token åºåˆ—ã€‚å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯è€Œè¨€ï¼Œå¤šè§†è§’ã€é«˜åˆ†è¾¨ç‡ã€è¿ç»­å¸§ï¼ˆè§†é¢‘ï¼‰æ˜¯æ„ŸçŸ¥ä»»åŠ¡çš„æ•°æ®ç‰¹ç‚¹ï¼Œè€Œå˜é•¿åºåˆ—ä»£è¡¨æ—¶å»¶ã€ä¸ç¨³å®šã€‚æ‰€ä»¥ä½œè€…ä»¥ BLIP-2 ç»“æ„ä¸ºåŸºç¡€ï¼Œå¼•å…¥ Stream-PETRï¼ˆä½œè€…ä¹‹å‰çš„å·¥ä½œï¼‰ï¼Œæ„å»ºç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„ 3D MLLMã€‚\u003c/li\u003e\n\u003cli\u003eè¿‡å»çš„ Benchmark å¤§å¤šé‡‡ç”¨ç®€å•çš„ QA çš„å½¢å¼è¿›è¡Œè¯„æµ‹ï¼Œå·²æœ‰å·¥ä½œè¯æ˜ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç›®å‰ open-loop è¯„æµ‹æ–¹å¼çš„å±€é™æ€§ã€‚å¦å¤–ï¼Œè¿™ç§è¯„æµ‹æ–¹å¼é©±åŠ¨çš„æ–¹æ³•ä¹Ÿæ— æ³•å®Œå…¨åˆ©ç”¨åˆ°å¤§è¯­è¨€æ¨¡å‹å¼ºå¤§çš„æ¶Œç°èƒ½åŠ›ã€‚å¯¹äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œç±»ä¼¼äºä¸–ç•Œæ¨¡å‹çš„åäº‹å®æ¨æ–­èƒ½åŠ›æ˜¯æ›´ç¬¦åˆäººç±»æ€è€ƒæ–¹å¼å’Œä¹ æƒ¯çš„ã€‚ä½œè€…å¸Œæœ›ä»¿ç…§ LLAVA çš„åšæ³•ï¼Œæå‡ºä¸€ç§é«˜æ•ˆçš„æ•°æ®æ„å»ºæ–¹å¼ï¼Œç”¨äºæ„å»ºå¤§è§„æ¨¡ VQA æ•°æ®é›†ï¼Œä¸€æ–¹é¢ç”¨äº MLLM çš„ Instruction-tuning è®­ç»ƒï¼Œå¦ä¸€æ–¹é¢ç”¨äºè¯„æµ‹ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"è´¡çŒ®\"\u003eè´¡çŒ®ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eä¸€ç§å…·æœ‰3d èƒ½åŠ›çš„vision-language modelç»“æ„ï¼Œå°†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„3dåœºæ™¯ä»»åŠ¡ï¼›\u003c/li\u003e\n\u003cli\u003eä¸€ç§åŸºäº GPT-4o çš„æ•°æ®æ„å»ºæ–¹æ³•ï¼Œç”¨äºç”Ÿæˆè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„ VQA é—®ç­”æ•°æ®ï¼ŒåŒ…æ‹¬åäº‹å®æ¨æ–­å½¢å¼çš„é—®ç­”ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"äºŒæ–¹æ³•\"\u003eäºŒ.æ–¹æ³•\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://picgo-1301748200.cos.ap-chengdu.myqcloud.com/image-20241214220821479.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"ç»“æ„æ€»è§ˆ\"\u003eç»“æ„æ€»è§ˆï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eå›¾åƒç¼–ç å™¨ï¼šä½œè€…é‡‡ç”¨çš„æ˜¯åŸºäº Clip ç»“æ„çš„ Eva-02 æ¨¡å‹ä½œä¸ºå›¾åƒç¼–ç å™¨ï¼Œé€šè¿‡å¤šè§†è§’å›¾åƒç‰¹å¾æå– 3d ä¿¡æ¯ï¼Œè¿™ä¸€éƒ¨åˆ†æ²¡å¤ªå¤šéœ€è¦è®²çš„ã€‚\u003c/li\u003e\n\u003cli\u003eQ-Former3Dï¼šå‚è€ƒ BLIP-2 ä¸­çš„ Q-Former ç»“æ„ï¼Œè¿™é‡Œä½œè€…æ•é”åœ°å‘ç°äº† Q-Former ç»“æ„å’Œ Petr ç³»åˆ—æ¨¡å‹ç»“æ„çš„ç›¸ä¼¼ä¹‹å¤„ï¼Œå°†ç»“æ„å¼•å…¥çš„åŒæ—¶ä¹Ÿå¼•å…¥äº† 3D ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä½œä¸ºè¾…åŠ©ç›‘ç£ã€‚\u003c/li\u003e\n\u003cli\u003eLLMï¼šä¹‹å‰çš„ç»“æ„çš„ä½œç”¨åœ¨äºæå– 3D ä¿¡æ¯ç‰¹å¾ï¼Œæœ€ç»ˆéœ€è¦å¯¹é½åˆ° LLM æ¨¡å‹èƒ½å¤Ÿç†è§£çš„ç‰¹å¾ç©ºé—´ï¼Œè¿›è¡Œ VQA é—®ç­”ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"q-former3d\"\u003eQ-Former3D:\u003c/h2\u003e\n\u003cp\u003eä½œä¸ºæœ€èƒ½ä½“ç°ä½œè€…è´¡çŒ®çš„æ¨¡å—ï¼Œè¿™ä¸€éƒ¨åˆ†é€‰æ‹© Stream-PETR å‡ºäºä»¥ä¸‹è€ƒè™‘ï¼šPETR æ‰€ä»£è¡¨çš„ç¨€ç– BEV å»ºæ¨¡æ–¹å¼ï¼Œé€‚ç”¨äºæ£€æµ‹ä»»åŠ¡ï¼Œç›¸æ¯”äºéœ€è¦æ„å»º dense bev feature çš„æ–¹æ³•æ¥è¯´ï¼Œéœ€è¦æ›´å°çš„è®¡ç®—é‡ï¼ŒåŒæ—¶åŠ å¿«æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼Œæ¯•ç«ŸOmniDrive çš„æ ¸å¿ƒåœ¨äºå¤šæ¨¡æ€å¤§æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ£€æµ‹ä»»åŠ¡ä»…ä½œä¸ºè¾…åŠ©ç›‘ç£ï¼Œæ‰€ä»¥å°½é‡ç®€åŒ–é™ä½å­˜åœ¨æ„Ÿã€‚\u003c/p\u003e","title":"OmniDrive è®ºæ–‡è§£è¯»"},{"content":"ä½œä¸ºè¿™ä¸ªblog çš„å¼€å§‹ ä»Šå¤©æ˜¯ 2024å¹´çš„12æœˆ15 æ—¥ï¼Œæ™´ï¼Œå¾®é£ï¼Œæœ‰ä¸€äº›å†·ã€‚\næˆ‘å’Œ coldeye ç»è¿‡ç®€å•çš„è®¨è®ºåå†³å®šåœ¨ä»Šå¤©å»ºç«‹ä¸€ä¸ªå±äºæˆ‘ä»¬è‡ªå·±çš„åšå®¢ã€‚\nåšå®¢é£æ ¼çš„é€‰æ‹©å°±å’Œæˆ‘ä»¬å†³å®šçš„è¿‡ç¨‹ä¸€æ ·è‰ç‡ï¼Œæˆ‘ä»¬é€‰æ‹©äº† Lil çš„åšå®¢åŒæ¬¾ä¸»é¢˜ï¼Œæˆ‘æƒ³ä¸»è¦åŸå› å¯èƒ½æ˜¯Lilæ˜¯æˆ‘çœ‹åˆ°çš„ç¬¬ä¸€ä¸ªåšå®¢ï¼Œå†…å®¹æ·±åº¦å’Œå†™ä½œé£æ ¼éƒ½ä»¤äººå°è±¡æ·±åˆ»ã€‚å¸Œæœ›èƒ½ä»¥æ­¤ä¸ºæˆ‘ä»¬è¿™ä¸ªåšå®¢çš„æ¦œæ ·ã€‚\nå…³äºè¿™ä¸ªåšå®¢çš„åˆå¿ƒå¾ˆç®€å•ï¼Œæˆ‘ä»¬ä¿©åœ¨å¶ç„¶çª¥è§å„ä½æŠ€æœ¯å¤§ä½¬ä»¬é•¿å¹´ç´¯æœˆçš„æƒŠäººç§¯ç´¯åï¼Œå¾ˆéš¾ä¸æƒ­æ„§äºè‡ªå·±å½“ä¸‹çš„åº¸åº¸ç¢Œç¢Œï¼Œæ„Ÿå¹è¿‡å»çœ‹ä¼¼å¿™ç¢Œçš„æ—¥å­å´å¹¶æ²¡æœ‰ç•™ä¸‹ä»€ä¹ˆè®°å½•ã€‚\nä¹Ÿè®¸æ˜¯ä¸ç”˜äºè™šåº¦å…‰é˜´ï¼Œä¹Ÿè®¸æ˜¯ä¸ºäº†å¯¹æŠ—è‡ªå·±æ—¥æ¸ä¸¥é‡çš„æ‹–å»¶ç—‡ï¼Œä¹Ÿè®¸æ˜¯ä»…ä»…æƒ³é”»ç‚¼ä¸€ä¸‹è‡ªå·±å¯¹ markdown è¯­æ³•çš„ä½¿ç”¨ï¼Œä¸ç®¡æ€ä¹ˆè¯´ï¼Œå¸Œæœ›å°†è¿™ä¸ªåšå®¢ä½œä¸ºè¿™ä¸ªæ—¶é—´ç‚¹\u0026quot;äººç”Ÿçš„ç»³ç»“\u0026quot;ï¼Œä»¥åå¦‚æœå›å¿†èµ·è¿™æ®µæ¼«é•¿é‡å¤çš„æ—¥å­ï¼Œèƒ½è¢«è¿™ä¸åŒå¹³å¸¸çš„ä¸€æ—¥æ‹¦æˆªä¸‹æ¥ã€‚\nä»¥åä¼šå®šæœŸæ›´æ–°ä¸€äº›æŠ€æœ¯åšå®¢ï¼Œé¢„æœŸæ˜¯è‡ªå·±æŸæ®µæ—¶é—´çš„ç ”ç©¶å†…å®¹ç›¸å…³ã€‚ç”±äºæˆ‘å’Œ coldeye ç ”ç©¶æ–¹å‘ä¸åŒï¼Œå¯èƒ½æ¯ç¯‡åšå®¢çš„å†…å®¹å’Œé£æ ¼è·¨åº¦è¿˜æ¯”è¾ƒå¤§ï¼Œè¿™æ ·å…¶å®æŒºå¥½ï¼Œä¼šè®©è¿™ä¸ªåšå®¢çš„å†…å®¹ä¸å¤ªæ— èŠã€‚\nä¸ç®¡ä¼šä¸ä¼šæœ‰äººçœ‹åˆ°è¿™ä¸ªåšå®¢ï¼Œè‡³å°‘æœŸå¾…ç€æœªæ¥çš„æ—¶é—´é‡Œè‡ªå·±èƒ½å¸¸æ¥çœ‹çœ‹ï¼Œä½“ä¼šä¸€ä¸‹æˆ‘ç°åœ¨å†™è¿™æ®µæ–‡å­—çš„å¿ƒæƒ…ï¼Œç›´è§‚æ„Ÿå—åˆ°è‡ªå·±çš„æˆé•¿ã€‚\nè¯·ä¸€å®šè¦ä¿æŒæ›´æ–°é¢‘ç‡ï¼Œåˆ«æµªè´¹äº† coldeye ä»Šå¤©æ­å»ºåšå®¢çš„åŠªåŠ›ï¼ˆæ­¤å¤„åº”è¯¥æœ‰ä¸€ä¸ªğŸ¤­ï¼‰ã€‚\næœ€è¿‘æ˜¯ç ”ä¸‰çš„ä¸Šå­¦æœŸï¼Œåˆšç»“æŸç§‹æ‹›çš„å…µè’é©¬ä¹±ï¼Œæˆ‘æš‚æ—¶å¯ä»¥ç®—æ˜¯å®šä¸‹äº†å»å¤„ï¼Œcoldeye åº”è¯¥è¿˜ä¼šå†å¿™ä¸€å°é˜µã€‚\nç¥æˆ‘å’Œä»–è¿˜æœ‰ Lucas å…ˆç”Ÿå¥½è¿ã€‚\näººç”Ÿæ²¡æœ‰è®°å½•ï¼Œå°±å¦‚åŒä¸€å¹…æ— è‰²çš„ç”»ã€‚\nâ€”â€”æ‰˜å°”æ–¯æ³°\n","permalink":"https://ouhaoten.github.io/posts/2024-12-15-introduction/","summary":"\u003ch2 id=\"ä½œä¸ºè¿™ä¸ªblog-çš„å¼€å§‹\"\u003eä½œä¸ºè¿™ä¸ªblog çš„å¼€å§‹\u003c/h2\u003e","title":"The begining"}]